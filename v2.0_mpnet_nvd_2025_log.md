--- CVE Severity Prediction Workflow ---

=== STAGE 1: DATA PREPARATION ===
✅ Garak report successfully converted to: data/garak/garak_report_flat.csv
--- Starting NVD Data Download ---

--- Starting NVD Data Parsing ---

Entries before duplicate removal: 5465
Entries after duplicate removal: 4968
✅ Parsing Complete. Saved 4968 unique entries to data/nvd_data/all_nvd_cves.pkl

=== STAGE 2: MODEL TRAINING ===

--- Training and Evaluation ---
Training on 4968 valid NVD entries.
Loading embedding model: 'all-mpnet-base-v2'...
model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]

Encoding all descriptions... (This may take a while)
Batches:   0%|          | 0/156 [00:00<?, ?it/s]

Applying SMOTE to balance the training data...

--- Training Logistic Regression ---
              precision    recall  f1-score   support

    Critical       0.62      0.67      0.65       268
        High       0.57      0.55      0.56       406
         Low       0.22      0.65      0.33        51
      Medium       0.70      0.56      0.62       517

    accuracy                           0.58      1242
   macro avg       0.53      0.61      0.54      1242
weighted avg       0.62      0.58      0.59      1242


--- Training Random Forest ---
              precision    recall  f1-score   support

    Critical       0.71      0.62      0.66       268
        High       0.58      0.59      0.58       406
         Low       0.46      0.31      0.37        51
      Medium       0.68      0.73      0.71       517

    accuracy                           0.64      1242
...
--- Training LightGBM (Tuned) ---
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
Output is truncated. View as a scrollable element or open in a text editor. Adjust cell output settings...
/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.
  warnings.warn(
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.074937 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 195840
[LightGBM] [Info] Number of data points in the train set: 6212, number of used features: 768
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
[LightGBM] [Info] Start training from score -1.386294
[LightGBM] [Info] Start training from score -1.386294
[LightGBM] [Info] Start training from score -1.386294
[LightGBM] [Info] Start training from score -1.386294
/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.
  warnings.warn(
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
              precision    recall  f1-score   support

    Critical       0.73      0.65      0.69       268
        High       0.58      0.60      0.59       406
         Low       0.57      0.25      0.35        51
      Medium       0.69      0.75      0.72       517

    accuracy                           0.66      1242
   macro avg       0.64      0.56      0.59      1242
weighted avg       0.66      0.66      0.66      1242


🏆 Best performing model is: LightGBM (Tuned) with F1-Score: 0.6555
✅ Best model saved to models/best_cvss_classifier_historic.pkl

=== STAGE 3: PREDICTION ===

--- Prediction on Garak Report ---
Embedding Garak report for prediction...
Batches:   0%|          | 0/190 [00:00<?, ?it/s]
/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.
  warnings.warn(
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
✅ Predictions saved to data/garak/garak_with_severity_historic.csv

--- Final Vulnerability Score (for FAILED test cases) ---
Calculating score based on 3037 failed test cases (out of 6074 total).

Severity Distribution (of Failures):
predicted_severity
Medium      2679
High         357
Critical       1
Name: count, dtype: int64

Total Raw Risk Score (from Failures): 13225
Normalized Report Vulnerability Score (0-100): 43.55

--- Workflow Finished ---