{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "fa0cd751484f416db940f6faebca1351": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2907706139894d2ab0c40b1709363043",
              "IPY_MODEL_e2efe32d4276423e90f1fd9502008d82",
              "IPY_MODEL_87bb54d1face428a840876ed1ab59141"
            ],
            "layout": "IPY_MODEL_a0fee4a978a6481e855cf1e937c35757"
          }
        },
        "2907706139894d2ab0c40b1709363043": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5532a7b74ed54861abd8de1572cf2af8",
            "placeholder": "​",
            "style": "IPY_MODEL_8959c319b5084dfdb5dbe1c03ac54d4e",
            "value": "Batches: 100%"
          }
        },
        "e2efe32d4276423e90f1fd9502008d82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e4ea9c0b352744da8b2946dd3ce54aa1",
            "max": 357,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b882271c8cba4bc6a43ddb423304e79c",
            "value": 357
          }
        },
        "87bb54d1face428a840876ed1ab59141": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8393da5b871945a585838f88ae269241",
            "placeholder": "​",
            "style": "IPY_MODEL_1f70c15696d94689ad7848a0d31ec30c",
            "value": " 357/357 [12:13&lt;00:00,  3.31it/s]"
          }
        },
        "a0fee4a978a6481e855cf1e937c35757": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5532a7b74ed54861abd8de1572cf2af8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8959c319b5084dfdb5dbe1c03ac54d4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e4ea9c0b352744da8b2946dd3ce54aa1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b882271c8cba4bc6a43ddb423304e79c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8393da5b871945a585838f88ae269241": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f70c15696d94689ad7848a0d31ec30c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2cce2be92f1046e2bb178aa391a609dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ed288d4c1f284ab5b3bd7ace632d224a",
              "IPY_MODEL_6f61215cadf44373af23a1afeee6c467",
              "IPY_MODEL_c6bd4cf57f5842c4a8158de418f52511"
            ],
            "layout": "IPY_MODEL_e71465683b534ecf9ea640a7715e6799"
          }
        },
        "ed288d4c1f284ab5b3bd7ace632d224a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a32df6ddb6b498fa86574d4d5d1041b",
            "placeholder": "​",
            "style": "IPY_MODEL_9ff0fd1095b94b47bd2e8d53518c1a25",
            "value": "Batches: 100%"
          }
        },
        "6f61215cadf44373af23a1afeee6c467": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9918f4082f294863ab353d1b49364163",
            "max": 190,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dd2e8d19978e45a282dc9b2bf6b801bf",
            "value": 190
          }
        },
        "c6bd4cf57f5842c4a8158de418f52511": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1464a0d3296b4db3bee145df7133640e",
            "placeholder": "​",
            "style": "IPY_MODEL_e9f826102edf4541b1c4fa8745f2a73b",
            "value": " 190/190 [13:27&lt;00:00,  1.43s/it]"
          }
        },
        "e71465683b534ecf9ea640a7715e6799": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a32df6ddb6b498fa86574d4d5d1041b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ff0fd1095b94b47bd2e8d53518c1a25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9918f4082f294863ab353d1b49364163": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd2e8d19978e45a282dc9b2bf6b801bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1464a0d3296b4db3bee145df7133640e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9f826102edf4541b1c4fa8745f2a73b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall torch torchvision torchaudio sentence-transformers transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OcCAPKl5SJZJ",
        "outputId": "adb76faf-0c3b-42fd-8b2f-8325b4665545"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: torch 2.6.0+cu124\n",
            "Uninstalling torch-2.6.0+cu124:\n",
            "  Would remove:\n",
            "    /usr/local/bin/torchfrtrace\n",
            "    /usr/local/bin/torchrun\n",
            "    /usr/local/lib/python3.11/dist-packages/functorch/*\n",
            "    /usr/local/lib/python3.11/dist-packages/torch-2.6.0+cu124.dist-info/*\n",
            "    /usr/local/lib/python3.11/dist-packages/torch/*\n",
            "    /usr/local/lib/python3.11/dist-packages/torchgen/*\n",
            "Proceed (Y/n)? y\n",
            "  Successfully uninstalled torch-2.6.0+cu124\n",
            "Found existing installation: torchvision 0.21.0+cu124\n",
            "Uninstalling torchvision-0.21.0+cu124:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.11/dist-packages/torchvision-0.21.0+cu124.dist-info/*\n",
            "    /usr/local/lib/python3.11/dist-packages/torchvision.libs/libcudart.41118559.so.12\n",
            "    /usr/local/lib/python3.11/dist-packages/torchvision.libs/libjpeg.1c1c4b09.so.8\n",
            "    /usr/local/lib/python3.11/dist-packages/torchvision.libs/libnvjpeg.02b6d700.so.12\n",
            "    /usr/local/lib/python3.11/dist-packages/torchvision.libs/libpng16.0364a1db.so.16\n",
            "    /usr/local/lib/python3.11/dist-packages/torchvision.libs/libsharpyuv.5c41a003.so.0\n",
            "    /usr/local/lib/python3.11/dist-packages/torchvision.libs/libwebp.54a0d02a.so.7\n",
            "    /usr/local/lib/python3.11/dist-packages/torchvision.libs/libz.d13a2644.so.1\n",
            "    /usr/local/lib/python3.11/dist-packages/torchvision/*\n",
            "Proceed (Y/n)? y\n",
            "  Successfully uninstalled torchvision-0.21.0+cu124\n",
            "Found existing installation: torchaudio 2.6.0+cu124\n",
            "Uninstalling torchaudio-2.6.0+cu124:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.11/dist-packages/torchaudio-2.6.0+cu124.dist-info/*\n",
            "    /usr/local/lib/python3.11/dist-packages/torchaudio/*\n",
            "    /usr/local/lib/python3.11/dist-packages/torio/*\n",
            "Proceed (Y/n)? y\n",
            "  Successfully uninstalled torchaudio-2.6.0+cu124\n",
            "Found existing installation: sentence-transformers 4.1.0\n",
            "Uninstalling sentence-transformers-4.1.0:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.11/dist-packages/sentence_transformers-4.1.0.dist-info/*\n",
            "    /usr/local/lib/python3.11/dist-packages/sentence_transformers/*\n",
            "Proceed (Y/n)? y\n",
            "  Successfully uninstalled sentence-transformers-4.1.0\n",
            "Found existing installation: transformers 4.52.4\n",
            "Uninstalling transformers-4.52.4:\n",
            "  Would remove:\n",
            "    /usr/local/bin/transformers\n",
            "    /usr/local/bin/transformers-cli\n",
            "    /usr/local/lib/python3.11/dist-packages/transformers-4.52.4.dist-info/*\n",
            "    /usr/local/lib/python3.11/dist-packages/transformers/*\n",
            "Proceed (Y/n)? y\n",
            "  Successfully uninstalled transformers-4.52.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install sentence-transformers torch pandas scikit-learn joblib requests lightgbm torchvision"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hs9Wa1kJSBJq",
        "outputId": "e9e7439e-059e-40fa-992b-89257db79b48"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sentence-transformers\n",
            "  Downloading sentence_transformers-4.1.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting torch\n",
            "  Downloading torch-2.7.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (29 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (1.5.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.11/dist-packages (4.5.0)\n",
            "Collecting torchvision\n",
            "  Downloading torchvision-0.22.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n",
            "Collecting transformers<5.0.0,>=4.41.0 (from sentence-transformers)\n",
            "  Downloading transformers-4.52.4-py3-none-any.whl.metadata (38 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.15.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.32.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.2.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Collecting sympy>=1.13.3 (from torch)\n",
            "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.6.77 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.6.77 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.6.80 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.5.1.17 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.6.4.1 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.3.0.4 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.7.77 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.7.1.2 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.5.4.2 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparselt-cu12==0.6.3 (from torch)\n",
            "  Downloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting nvidia-nccl-cu12==2.26.2 (from torch)\n",
            "  Downloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.6.77 (from torch)\n",
            "  Downloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nvjitlink-cu12==12.6.85 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufile-cu12==1.11.1.6 (from torch)\n",
            "  Downloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting triton==3.3.1 (from torch)\n",
            "  Downloading triton-3.3.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from triton==3.3.1->torch) (75.2.0)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.4.26)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading sentence_transformers-4.1.0-py3-none-any.whl (345 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.7/345.7 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.7.1-cp311-cp311-manylinux_2_28_x86_64.whl (821.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m821.2/821.2 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (393.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m393.1/393.1 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m85.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (23.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (897 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.7/897.7 kB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl (571.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m571.0/571.0 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (200.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.2/200.2 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m56.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (158.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.2/158.2 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (216.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.6/216.6 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl (156.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.8/156.8 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (201.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.3/201.3 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (19.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m84.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.3/89.3 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.3.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (155.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.7/155.7 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchvision-0.22.1-cp311-cp311-manylinux_2_28_x86_64.whl (7.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m70.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m43.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.52.4-py3-none-any.whl (10.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.5/10.5 MB\u001b[0m \u001b[31m70.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-cusparselt-cu12, triton, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, transformers, torch, torchvision, sentence-transformers\n",
            "  Attempting uninstall: nvidia-cusparselt-cu12\n",
            "    Found existing installation: nvidia-cusparselt-cu12 0.6.2\n",
            "    Uninstalling nvidia-cusparselt-cu12-0.6.2:\n",
            "      Successfully uninstalled nvidia-cusparselt-cu12-0.6.2\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.2.0\n",
            "    Uninstalling triton-3.2.0:\n",
            "      Successfully uninstalled triton-3.2.0\n",
            "  Attempting uninstall: sympy\n",
            "    Found existing installation: sympy 1.13.1\n",
            "    Uninstalling sympy-1.13.1:\n",
            "      Successfully uninstalled sympy-1.13.1\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.4.127\n",
            "    Uninstalling nvidia-nvtx-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.21.5\n",
            "    Uninstalling nvidia-nccl-cu12-2.21.5:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "fastai 2.7.19 requires torch<2.7,>=1.10, but you have torch 2.7.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.6.4.1 nvidia-cuda-cupti-cu12-12.6.80 nvidia-cuda-nvrtc-cu12-12.6.77 nvidia-cuda-runtime-cu12-12.6.77 nvidia-cudnn-cu12-9.5.1.17 nvidia-cufft-cu12-11.3.0.4 nvidia-cufile-cu12-1.11.1.6 nvidia-curand-cu12-10.3.7.77 nvidia-cusolver-cu12-11.7.1.2 nvidia-cusparse-cu12-12.5.4.2 nvidia-cusparselt-cu12-0.6.3 nvidia-nccl-cu12-2.26.2 nvidia-nvjitlink-cu12-12.6.85 nvidia-nvtx-cu12-12.6.77 sentence-transformers-4.1.0 sympy-1.14.0 torch-2.7.1 torchvision-0.22.1 transformers-4.52.4 triton-3.3.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "fa0cd751484f416db940f6faebca1351",
            "2907706139894d2ab0c40b1709363043",
            "e2efe32d4276423e90f1fd9502008d82",
            "87bb54d1face428a840876ed1ab59141",
            "a0fee4a978a6481e855cf1e937c35757",
            "5532a7b74ed54861abd8de1572cf2af8",
            "8959c319b5084dfdb5dbe1c03ac54d4e",
            "e4ea9c0b352744da8b2946dd3ce54aa1",
            "b882271c8cba4bc6a43ddb423304e79c",
            "8393da5b871945a585838f88ae269241",
            "1f70c15696d94689ad7848a0d31ec30c",
            "2cce2be92f1046e2bb178aa391a609dc",
            "ed288d4c1f284ab5b3bd7ace632d224a",
            "6f61215cadf44373af23a1afeee6c467",
            "c6bd4cf57f5842c4a8158de418f52511",
            "e71465683b534ecf9ea640a7715e6799",
            "0a32df6ddb6b498fa86574d4d5d1041b",
            "9ff0fd1095b94b47bd2e8d53518c1a25",
            "9918f4082f294863ab353d1b49364163",
            "dd2e8d19978e45a282dc9b2bf6b801bf",
            "1464a0d3296b4db3bee145df7133640e",
            "e9f826102edf4541b1c4fa8745f2a73b"
          ]
        },
        "id": "XpAQ8F0vR_LV",
        "outputId": "7ea962a4-b60e-4523-941e-31a56fbf245c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- CVE Severity Prediction Workflow ---\n",
            "\n",
            "=== STAGE 1: DATA PREPARATION ===\n",
            "Downloading sample Garak report...\n",
            "✅ Downloaded: data/4.0/garak/garak.report.jsonl\n",
            "✅ Garak report successfully converted to: data/4.0/garak/garak_report_flat.csv\n",
            "--- Starting NVD Data Download ---\n",
            "Downloading: nvdcve-1.1-2002.json.gz\n",
            "Downloading: nvdcve-1.1-2003.json.gz\n",
            "Downloading: nvdcve-1.1-2004.json.gz\n",
            "Downloading: nvdcve-1.1-2005.json.gz\n",
            "Downloading: nvdcve-1.1-2006.json.gz\n",
            "Downloading: nvdcve-1.1-2007.json.gz\n",
            "Downloading: nvdcve-1.1-2008.json.gz\n",
            "Downloading: nvdcve-1.1-2009.json.gz\n",
            "Downloading: nvdcve-1.1-2010.json.gz\n",
            "Downloading: nvdcve-1.1-2011.json.gz\n",
            "Downloading: nvdcve-1.1-2012.json.gz\n",
            "Downloading: nvdcve-1.1-2013.json.gz\n",
            "Downloading: nvdcve-1.1-2014.json.gz\n",
            "Downloading: nvdcve-1.1-2015.json.gz\n",
            "Downloading: nvdcve-1.1-2016.json.gz\n",
            "Downloading: nvdcve-1.1-2017.json.gz\n",
            "Downloading: nvdcve-1.1-2018.json.gz\n",
            "Downloading: nvdcve-1.1-2019.json.gz\n",
            "Downloading: nvdcve-1.1-2020.json.gz\n",
            "Downloading: nvdcve-1.1-2021.json.gz\n",
            "Downloading: nvdcve-1.1-2022.json.gz\n",
            "Downloading: nvdcve-1.1-2023.json.gz\n",
            "Downloading: nvdcve-1.1-2024.json.gz\n",
            "Downloading: nvdcve-1.1-2025.json.gz\n",
            "\n",
            "--- Starting NVD Data Parsing ---\n",
            "Parsing nvdcve-1.1-2002.json.gz...\n",
            "Parsing nvdcve-1.1-2003.json.gz...\n",
            "Parsing nvdcve-1.1-2004.json.gz...\n",
            "Parsing nvdcve-1.1-2005.json.gz...\n",
            "Parsing nvdcve-1.1-2006.json.gz...\n",
            "Parsing nvdcve-1.1-2007.json.gz...\n",
            "Parsing nvdcve-1.1-2008.json.gz...\n",
            "Parsing nvdcve-1.1-2009.json.gz...\n",
            "Parsing nvdcve-1.1-2010.json.gz...\n",
            "Parsing nvdcve-1.1-2011.json.gz...\n",
            "Parsing nvdcve-1.1-2012.json.gz...\n",
            "Parsing nvdcve-1.1-2013.json.gz...\n",
            "Parsing nvdcve-1.1-2014.json.gz...\n",
            "Parsing nvdcve-1.1-2015.json.gz...\n",
            "Parsing nvdcve-1.1-2016.json.gz...\n",
            "Parsing nvdcve-1.1-2017.json.gz...\n",
            "Parsing nvdcve-1.1-2018.json.gz...\n",
            "Parsing nvdcve-1.1-2019.json.gz...\n",
            "Parsing nvdcve-1.1-2020.json.gz...\n",
            "Parsing nvdcve-1.1-2021.json.gz...\n",
            "Parsing nvdcve-1.1-2022.json.gz...\n",
            "Parsing nvdcve-1.1-2023.json.gz...\n",
            "Parsing nvdcve-1.1-2024.json.gz...\n",
            "Parsing nvdcve-1.1-2025.json.gz...\n",
            "\n",
            "Entries before duplicate removal: 155734\n",
            "Entries after duplicate removal: 146631\n",
            "✅ Parsing Complete. Saved 146631 unique entries to data/4.0/nvd_data/all_nvd_cves.pkl\n",
            "\n",
            "=== STAGE 2: MODEL TRAINING ===\n",
            "\n",
            "--- Training and Evaluation with Undersampling ---\n",
            "Loaded 146631 valid NVD entries.\n",
            "\n",
            "Smallest class size is 2855. Undersampling all classes to this size.\n",
            "Original dataset distribution:\n",
            " severity\n",
            "Medium      64210\n",
            "High        56874\n",
            "Critical    22692\n",
            "Low          2855\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Balanced dataset distribution:\n",
            " severity\n",
            "Low         2855\n",
            "High        2855\n",
            "Medium      2855\n",
            "Critical    2855\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Loading embedding model: 'all-MiniLM-L6-v2'...\n",
            "Encoding all descriptions from the balanced dataset...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/357 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fa0cd751484f416db940f6faebca1351"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training on 8565 samples, testing on 2855 samples.\n",
            "\n",
            "--- Training Logistic Regression ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Critical       0.64      0.73      0.68       714\n",
            "        High       0.54      0.47      0.50       713\n",
            "         Low       0.72      0.71      0.71       714\n",
            "      Medium       0.64      0.65      0.65       714\n",
            "\n",
            "    accuracy                           0.64      2855\n",
            "   macro avg       0.64      0.64      0.64      2855\n",
            "weighted avg       0.64      0.64      0.64      2855\n",
            "\n",
            "\n",
            "--- Training Random Forest ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Critical       0.71      0.67      0.69       714\n",
            "        High       0.58      0.51      0.54       713\n",
            "         Low       0.65      0.79      0.72       714\n",
            "      Medium       0.68      0.66      0.67       714\n",
            "\n",
            "    accuracy                           0.66      2855\n",
            "   macro avg       0.66      0.66      0.65      2855\n",
            "weighted avg       0.66      0.66      0.65      2855\n",
            "\n",
            "\n",
            "--- Training LightGBM (Tuned) ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.081990 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 97920\n",
            "[LightGBM] [Info] Number of data points in the train set: 8565, number of used features: 384\n",
            "[LightGBM] [Info] Start training from score -1.386411\n",
            "[LightGBM] [Info] Start training from score -1.385944\n",
            "[LightGBM] [Info] Start training from score -1.386411\n",
            "[LightGBM] [Info] Start training from score -1.386411\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Critical       0.71      0.75      0.73       714\n",
            "        High       0.62      0.58      0.60       713\n",
            "         Low       0.75      0.78      0.76       714\n",
            "      Medium       0.71      0.70      0.70       714\n",
            "\n",
            "    accuracy                           0.70      2855\n",
            "   macro avg       0.70      0.70      0.70      2855\n",
            "weighted avg       0.70      0.70      0.70      2855\n",
            "\n",
            "\n",
            "🏆 Best performing model is: LightGBM (Tuned) with F1-Score: 0.6996\n",
            "✅ Best model saved to models/4.0/best_cvss_classifier_historic.pkl\n",
            "\n",
            "=== STAGE 3: PREDICTION ===\n",
            "\n",
            "--- Prediction on Garak Report ---\n",
            "Embedding Garak report for prediction...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/190 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2cce2be92f1046e2bb178aa391a609dc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Predictions saved to data/4.0/garak/garak_with_severity_historic.csv\n",
            "\n",
            "--- Final Vulnerability Score (for FAILED test cases) ---\n",
            "Calculating score based on 3037 failed test cases (out of 6074 total).\n",
            "\n",
            "Severity Distribution (of Failures):\n",
            "predicted_severity\n",
            "Low         2675\n",
            "High         226\n",
            "Medium       106\n",
            "Critical      30\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Total Raw Risk Score (from Failures): 4981\n",
            "Normalized Report Vulnerability Score (0-100): 16.40\n",
            "\n",
            "--- Workflow Finished ---\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "import gzip\n",
        "import os\n",
        "import requests\n",
        "import joblib\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "import csv\n",
        "import urllib.request\n",
        "import zipfile\n",
        "\n",
        "# Text Embedding and ML Models\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# The classifiers we will compare\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import lightgbm as lgb\n",
        "from lightgbm.callback import early_stopping\n",
        "\n",
        "# imblearn is no longer needed for undersampling as we are doing it manually\n",
        "# from imblearn.over_sampling import SMOTE\n",
        "\n",
        "\n",
        "# --- Configuration for file paths ---\n",
        "# Base directories\n",
        "DATA_DIR = Path(\"data\")\n",
        "MODELS_DIR = Path(\"models\")\n",
        "VERSION = \"4.0\"\n",
        "\n",
        "\n",
        "# Subdirectories for data\n",
        "NVD_DATA_DIR = DATA_DIR / VERSION / \"nvd_data\"\n",
        "GARAK_DATA_DIR = DATA_DIR / VERSION / \"garak\"\n",
        "\n",
        "# Specific file paths\n",
        "PARSED_DATA_PATH = NVD_DATA_DIR / f\"all_nvd_cves.pkl\"\n",
        "GARAK_REPORT_JSONL = GARAK_DATA_DIR / \"garak.report.jsonl\"\n",
        "GARAK_REPORT_CSV = GARAK_DATA_DIR / \"garak_report_flat.csv\"\n",
        "\n",
        "# Model file paths\n",
        "MODEL_PATH = MODELS_DIR /VERSION/ \"best_cvss_classifier_historic.pkl\"\n",
        "LABEL_ENCODER_PATH = MODELS_DIR /VERSION /\"cvss_label_encoder_historic.pkl\"\n",
        "\n",
        "\n",
        "# ----------------------------------------\n",
        "# STEP 1A: Process Garak Report\n",
        "# ----------------------------------------\n",
        "def process_garak_report():\n",
        "    \"\"\"\n",
        "    Downloads a sample Garak report if not present, and converts it\n",
        "    from .jsonl format to a flattened .csv file.\n",
        "    \"\"\"\n",
        "    GARAK_DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    url = \"https://gist.githubusercontent.com/shubhobm/9fa52d71c8bb36bfb888eee2ba3d18f2/raw/ef1808e6d3b26002d9b046e6c120d438adf49008/gpt35-0906.report.jsonl\"\n",
        "    if not GARAK_REPORT_JSONL.exists():\n",
        "        print(\"Downloading sample Garak report...\")\n",
        "        urllib.request.urlretrieve(url, GARAK_REPORT_JSONL)\n",
        "        print(f\"✅ Downloaded: {GARAK_REPORT_JSONL}\")\n",
        "\n",
        "    def parse_status(status_code):\n",
        "        return {1: \"Pass\", 2: \"Fail\"}.get(status_code, \"Not Evaluated\")\n",
        "\n",
        "    def extract_input_output(record):\n",
        "        turns = record.get(\"notes\", {}).get(\"turns\", [])\n",
        "        if turns:\n",
        "            attacker = \" | \".join([msg.strip().replace(\"\\n\", \" \") for role, msg in turns if role == \"probe\"])\n",
        "            bot = \" | \".join([msg.strip().replace(\"\\n\", \" \") for role, msg in turns if role == \"model\"])\n",
        "            return attacker, bot\n",
        "        prompt = record.get(\"prompt\", \"\").strip().replace(\"\\n\", \" \")\n",
        "        outputs = \" | \".join([o.strip().replace(\"\\n\", \" \") for o in record.get(\"outputs\", [])])\n",
        "        return prompt, outputs\n",
        "\n",
        "    with open(GARAK_REPORT_JSONL, \"r\", encoding=\"utf-8\") as infile, \\\n",
        "         open(GARAK_REPORT_CSV, \"w\", newline='', encoding=\"utf-8\") as outfile:\n",
        "\n",
        "        fieldnames = [\"uuid\", \"probe_classname\", \"attacker_input\", \"target_bot_response\", \"status\", \"goal\", \"trigger\"]\n",
        "        writer = csv.DictWriter(outfile, fieldnames=fieldnames)\n",
        "        writer.writeheader()\n",
        "\n",
        "        for line in infile:\n",
        "            record = json.loads(line)\n",
        "            if record.get(\"entry_type\") != \"attempt\":\n",
        "                continue\n",
        "\n",
        "            attacker_input, bot_response = extract_input_output(record)\n",
        "            writer.writerow({\n",
        "                \"uuid\": record.get(\"uuid\", \"\"),\n",
        "                \"probe_classname\": record.get(\"probe_classname\", \"\"),\n",
        "                \"attacker_input\": attacker_input,\n",
        "                \"target_bot_response\": bot_response,\n",
        "                \"status\": parse_status(record.get(\"status\")),\n",
        "                \"goal\": record.get(\"goal\", \"\"),\n",
        "                \"trigger\": record.get(\"notes\", {}).get(\"trigger\", \"\")\n",
        "            })\n",
        "    print(f\"✅ Garak report successfully converted to: {GARAK_REPORT_CSV}\")\n",
        "\n",
        "\n",
        "# ----------------------------------------\n",
        "# STEP 1B: Download and Parse All Historical NVD Data\n",
        "# ----------------------------------------\n",
        "def download_and_parse_all_nvd_data():\n",
        "    \"\"\"\n",
        "    Downloads all NVD CVE data, parses them, removes duplicates, and saves\n",
        "    the result to a pickle file.\n",
        "    \"\"\"\n",
        "    NVD_DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
        "    BASE_URL = \"https://nvd.nist.gov/feeds/json/cve/1.1/\"\n",
        "    START_YEAR, CURRENT_YEAR = 2002, datetime.now().year\n",
        "\n",
        "    print(\"--- Starting NVD Data Download ---\")\n",
        "    for year in range(START_YEAR, CURRENT_YEAR + 1):\n",
        "        filename = f\"nvdcve-1.1-{year}.json.gz\"\n",
        "        download_path = NVD_DATA_DIR / filename\n",
        "        if download_path.exists(): continue\n",
        "        print(f\"Downloading: {filename}\")\n",
        "        try:\n",
        "            response = requests.get(f\"{BASE_URL}{filename}\", stream=True, timeout=30)\n",
        "            if response.status_code == 200:\n",
        "                with open(download_path, 'wb') as f: f.writelines(response.iter_content(8192))\n",
        "            else: print(f\" -> Failed: HTTP {response.status_code}\")\n",
        "        except requests.RequestException as e: print(f\" -> Error: {e}\")\n",
        "\n",
        "    print(\"\\n--- Starting NVD Data Parsing ---\")\n",
        "    parsed_cve_list = []\n",
        "    for file_path in sorted(NVD_DATA_DIR.glob('*.json.gz')):\n",
        "        print(f\"Parsing {file_path.name}...\")\n",
        "        with gzip.open(file_path, 'rt', encoding='utf-8') as f:\n",
        "            cve_data = json.load(f)\n",
        "        for item in cve_data.get(\"CVE_Items\", []):\n",
        "            description = next((d[\"value\"] for d in item.get(\"cve\", {}).get(\"description\", {}).get(\"description_data\", []) if d.get(\"lang\") == \"en\"), \"\")\n",
        "            impact = item.get(\"impact\", {})\n",
        "            severity = impact.get('baseMetricV3', {}).get('cvssV3', {}).get('baseSeverity') or impact.get('baseMetricV2', {}).get('severity')\n",
        "            # MODIFIED: Also extract the published date to identify recent CVEs\n",
        "            published_date = item.get('publishedDate')\n",
        "            if description and severity and published_date:\n",
        "                parsed_cve_list.append({\n",
        "                    \"description\": description.strip(),\n",
        "                    \"severity\": severity.strip().capitalize(),\n",
        "                    \"publishedDate\": published_date\n",
        "                })\n",
        "\n",
        "    df = pd.DataFrame(parsed_cve_list)\n",
        "    print(f\"\\nEntries before duplicate removal: {len(df)}\")\n",
        "    df.drop_duplicates(subset=['description'], keep='last', inplace=True)\n",
        "    print(f\"Entries after duplicate removal: {len(df)}\")\n",
        "    df.to_pickle(PARSED_DATA_PATH)\n",
        "    print(f\"✅ Parsing Complete. Saved {len(df)} unique entries to {PARSED_DATA_PATH}\")\n",
        "\n",
        "\n",
        "# ----------------------------------------\n",
        "# STEP 2: Find the Best Classifier and Train It\n",
        "# ----------------------------------------\n",
        "def train_and_evaluate_models():\n",
        "    \"\"\"\n",
        "    Loads data, creates a balanced dataset by undersampling the majority classes\n",
        "    (keeping the most recent data), then splits this balanced set for training\n",
        "    and evaluation.\n",
        "    \"\"\"\n",
        "    if not PARSED_DATA_PATH.exists():\n",
        "        print(f\"Error: Parsed data not found at {PARSED_DATA_PATH}. Please run the 'data_prep' workflow first.\")\n",
        "        return None, None, None\n",
        "\n",
        "    print(f\"\\n--- Training and Evaluation with Undersampling ---\")\n",
        "    df = pd.read_pickle(PARSED_DATA_PATH).dropna()\n",
        "    print(f\"Loaded {len(df)} valid NVD entries.\")\n",
        "\n",
        "    # --- CORRECTED METHOD: Undersample BEFORE splitting ---\n",
        "    # 1. Convert 'publishedDate' to datetime objects to allow sorting\n",
        "    df['publishedDate'] = pd.to_datetime(df['publishedDate'])\n",
        "\n",
        "    # 2. Sort by date so newest entries are first\n",
        "    df = df.sort_values('publishedDate', ascending=False)\n",
        "\n",
        "    # 3. Determine the size of the smallest class\n",
        "    n_samples = df['severity'].value_counts().min()\n",
        "    print(f\"\\nSmallest class size is {n_samples}. Undersampling all classes to this size.\")\n",
        "    print(\"Original dataset distribution:\\n\", df['severity'].value_counts())\n",
        "\n",
        "    # 4. Group by severity and take the `n_samples` most recent entries from each group\n",
        "    df_balanced = df.groupby('severity').head(n_samples)\n",
        "\n",
        "    # 5. Shuffle the balanced dataset to ensure randomness\n",
        "    df_balanced = df_balanced.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "    print(\"\\nBalanced dataset distribution:\\n\", df_balanced['severity'].value_counts())\n",
        "\n",
        "    # 6. Prepare the final text list and labels from the balanced dataframe\n",
        "    X_text = df_balanced['description'].tolist()\n",
        "    y_labels = df_balanced['severity'].tolist()\n",
        "\n",
        "    # --- End of Undersampling Modification ---\n",
        "\n",
        "    print(\"\\nLoading embedding model: 'all-MiniLM-L6-v2'...\")\n",
        "    embed_model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "\n",
        "    print(\"Encoding all descriptions from the balanced dataset...\")\n",
        "    X_embeddings = embed_model.encode(X_text, show_progress_bar=True)\n",
        "\n",
        "    # Encode the labels\n",
        "    le = LabelEncoder()\n",
        "    y_encoded = le.fit_transform(y_labels)\n",
        "\n",
        "    # 7. Now split the balanced and encoded data into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X_embeddings, y_encoded, test_size=0.25, random_state=42, stratify=y_encoded\n",
        "    )\n",
        "    print(f\"\\nTraining on {len(X_train)} samples, testing on {len(X_test)} samples.\")\n",
        "\n",
        "    classifiers = {\n",
        "        \"Logistic Regression\": LogisticRegression(max_iter=2000, random_state=42),\n",
        "        \"Random Forest\": RandomForestClassifier(n_jobs=-1, random_state=42, n_estimators=100),\n",
        "        \"LightGBM (Tuned)\": lgb.LGBMClassifier(\n",
        "            n_estimators=1000,\n",
        "            learning_rate=0.05,\n",
        "            num_leaves=31,\n",
        "            random_state=42,\n",
        "            n_jobs=-1,\n",
        "            colsample_bytree=0.8,\n",
        "            subsample=0.8,\n",
        "            reg_alpha=0.1,\n",
        "            reg_lambda=0.1\n",
        "        )\n",
        "    }\n",
        "\n",
        "    best_f1, best_model_name, best_classifier_obj = -1, \"\", None\n",
        "    for name, clf in classifiers.items():\n",
        "        print(f\"\\n--- Training {name} ---\")\n",
        "        fit_params = {}\n",
        "        if \"LightGBM\" in name:\n",
        "            # The validation set for early stopping should come from the split data\n",
        "            fit_params = {\"eval_set\": [(X_test, y_test)], \"callbacks\": [early_stopping(20, verbose=False)]}\n",
        "\n",
        "        clf.fit(X_train, y_train, **fit_params)\n",
        "\n",
        "        y_pred = clf.predict(X_test)\n",
        "        report = classification_report(y_test, y_pred, output_dict=True, zero_division=0)\n",
        "        f1_score = report[\"weighted avg\"][\"f1-score\"]\n",
        "        if f1_score > best_f1:\n",
        "            best_f1, best_model_name, best_classifier_obj = f1_score, name, clf\n",
        "        print(classification_report(y_test, y_pred, target_names=le.classes_, zero_division=0))\n",
        "\n",
        "    print(f\"\\n🏆 Best performing model is: {best_model_name} with F1-Score: {best_f1:.4f}\")\n",
        "\n",
        "    MODELS_DIR.mkdir(parents=True, exist_ok=True)\n",
        "    MODEL_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
        "    joblib.dump(best_classifier_obj, MODEL_PATH)\n",
        "    joblib.dump(le, LABEL_ENCODER_PATH)\n",
        "    print(f\"✅ Best model saved to {MODEL_PATH}\")\n",
        "\n",
        "    return embed_model, best_classifier_obj, le\n",
        "\n",
        "# ----------------------------------------\n",
        "# STEP 3: Predict using a saved model\n",
        "# ----------------------------------------\n",
        "def predict_on_garak(embed_model=None, classifier=None, label_encoder=None):\n",
        "    if not GARAK_REPORT_CSV.exists():\n",
        "        print(f\"Error: Garak CSV not found. Please run the 'data_prep' workflow first.\")\n",
        "        return\n",
        "\n",
        "    if not all([embed_model, classifier, label_encoder]):\n",
        "        print(f\"Loading models from disk...\")\n",
        "        if not MODEL_PATH.exists():\n",
        "            print(f\"Error: Model file not found at {MODEL_PATH}. Please run the 'train' workflow first.\")\n",
        "            return\n",
        "        classifier = joblib.load(MODEL_PATH)\n",
        "        label_encoder = joblib.load(LABEL_ENCODER_PATH)\n",
        "        # Use the same model for consistency\n",
        "        embed_model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "\n",
        "    print(\"\\n--- Prediction on Garak Report ---\")\n",
        "    df = pd.read_csv(GARAK_REPORT_CSV)\n",
        "    df[\"full_text\"] = df[\"attacker_input\"].fillna('') + \" \" + df[\"target_bot_response\"].fillna('')\n",
        "\n",
        "    print(\"Embedding Garak report for prediction...\")\n",
        "    embeddings = embed_model.encode(df[\"full_text\"].tolist(), show_progress_bar=True)\n",
        "\n",
        "    probabilities = classifier.predict_proba(embeddings)\n",
        "    df[\"predicted_severity\"] = label_encoder.inverse_transform(np.argmax(probabilities, axis=1))\n",
        "    df[\"confidence_score\"] = np.round(np.max(probabilities, axis=1), 4)\n",
        "    for i, name in enumerate(label_encoder.classes_):\n",
        "        df[f'prob_{name.lower()}'] = np.round(probabilities[:, i], 4)\n",
        "\n",
        "    output_path = GARAK_DATA_DIR / \"garak_with_severity_historic.csv\"\n",
        "    df.to_csv(output_path, index=False)\n",
        "    print(f\"✅ Predictions saved to {output_path}\")\n",
        "\n",
        "    print(\"\\n--- Final Vulnerability Score (for FAILED test cases) ---\")\n",
        "    failed_df = df[df['status'] == 'Fail'].copy()\n",
        "\n",
        "    if failed_df.empty:\n",
        "        print(\"No failed test cases found in the report. No score to calculate.\")\n",
        "        return\n",
        "\n",
        "    print(f\"Calculating score based on {len(failed_df)} failed test cases (out of {len(df)} total).\")\n",
        "    severity_map = {'Critical': 10, 'High': 7, 'Medium': 4, 'Low': 1}\n",
        "    severity_counts = failed_df['predicted_severity'].value_counts()\n",
        "    total_score = sum(count * severity_map.get(s, 0) for s, count in severity_counts.items())\n",
        "    max_possible_score = len(failed_df) * 10\n",
        "    normalized_score = (total_score / max_possible_score) * 100 if max_possible_score > 0 else 0\n",
        "\n",
        "    print(\"\\nSeverity Distribution (of Failures):\")\n",
        "    print(severity_counts)\n",
        "    print(f\"\\nTotal Raw Risk Score (from Failures): {total_score}\")\n",
        "    print(f\"Normalized Report Vulnerability Score (0-100): {normalized_score:.2f}\")\n",
        "\n",
        "# ----------------------------------------\n",
        "# STEP 4: Create a ZIP Archive of the Results\n",
        "# ----------------------------------------\n",
        "def create_archive():\n",
        "    print(\"\\n--- Creating ZIP Archive ---\")\n",
        "    archive_name = \"cve_prediction_archive\"\n",
        "\n",
        "    with zipfile.ZipFile(f\"{archive_name}.zip\", 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
        "        for folder in [DATA_DIR, MODELS_DIR]:\n",
        "            if folder.exists() and folder.is_dir():\n",
        "                for file_path in folder.rglob('*'):\n",
        "                    zipf.write(file_path, arcname=file_path.relative_to(Path.cwd()))\n",
        "                print(f\"Archived folder: {folder}\")\n",
        "            else:\n",
        "                print(f\"Warning: Folder '{folder}' not found. Skipping.\")\n",
        "\n",
        "    print(f\"✅ Archive created successfully: {archive_name}.zip\")\n",
        "\n",
        "\n",
        "# ----------------------------------------\n",
        "# MAIN EXECUTION WORKFLOW\n",
        "# ----------------------------------------\n",
        "def run_workflow(data_prep=False, train=False, predict=False, archive=False):\n",
        "    \"\"\"\n",
        "    Controls the main execution flow of the script.\n",
        "    Set flags to True for the steps you want to run.\n",
        "    \"\"\"\n",
        "    print(\"--- CVE Severity Prediction Workflow ---\")\n",
        "\n",
        "    if data_prep:\n",
        "        print(\"\\n=== STAGE 1: DATA PREPARATION ===\")\n",
        "        process_garak_report()\n",
        "        download_and_parse_all_nvd_data()\n",
        "\n",
        "    embed_model, classifier, label_encoder = None, None, None\n",
        "    if train:\n",
        "        print(\"\\n=== STAGE 2: MODEL TRAINING ===\")\n",
        "        embed_model, classifier, label_encoder = train_and_evaluate_models()\n",
        "\n",
        "    if predict:\n",
        "        print(\"\\n=== STAGE 3: PREDICTION ===\")\n",
        "        predict_on_garak(embed_model, classifier, label_encoder)\n",
        "\n",
        "    if archive:\n",
        "        print(\"\\n=== STAGE 4: ARCHIVING ===\")\n",
        "        create_archive()\n",
        "\n",
        "    print(\"\\n--- Workflow Finished ---\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # --- Configure your desired workflow here ---\n",
        "\n",
        "    # To get good results, you MUST run data_prep=True first.\n",
        "    # On the first run, it's recommended to do all three main steps.\n",
        "    run_workflow(data_prep=True, train=True, predict=True)\n",
        "\n",
        "    # After the first run, you can comment out the line above and\n",
        "    # uncomment one of the following lines to run specific tasks.\n",
        "\n",
        "    # Example: Just run prediction using existing models\n",
        "    # run_workflow(predict=True)\n",
        "\n",
        "    # Example: Just create an archive of existing results\n",
        "    # run_workflow(archive=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r data.zip data/\n",
        "!zip -r models.zip models/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4p9DZZ4VgSgl",
        "outputId": "7d531969-d0a6-40e1-af8d-2bf1e502886a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: data/ (stored 0%)\n",
            "  adding: data/4.0/ (stored 0%)\n",
            "  adding: data/4.0/nvd_data/ (stored 0%)\n",
            "  adding: data/4.0/nvd_data/nvdcve-1.1-2013.json.gz (deflated 2%)\n",
            "  adding: data/4.0/nvd_data/nvdcve-1.1-2005.json.gz (deflated 2%)\n",
            "  adding: data/4.0/nvd_data/nvdcve-1.1-2021.json.gz (deflated 4%)\n",
            "  adding: data/4.0/nvd_data/nvdcve-1.1-2017.json.gz (deflated 4%)\n",
            "  adding: data/4.0/nvd_data/nvdcve-1.1-2004.json.gz (stored 0%)\n",
            "  adding: data/4.0/nvd_data/nvdcve-1.1-2020.json.gz (deflated 4%)\n",
            "  adding: data/4.0/nvd_data/nvdcve-1.1-2016.json.gz (deflated 3%)\n",
            "  adding: data/4.0/nvd_data/nvdcve-1.1-2007.json.gz (deflated 0%)\n",
            "  adding: data/4.0/nvd_data/nvdcve-1.1-2022.json.gz (deflated 3%)\n",
            "  adding: data/4.0/nvd_data/nvdcve-1.1-2024.json.gz (deflated 1%)\n",
            "  adding: data/4.0/nvd_data/all_nvd_cves.pkl (deflated 78%)\n",
            "  adding: data/4.0/nvd_data/nvdcve-1.1-2023.json.gz (deflated 3%)\n",
            "  adding: data/4.0/nvd_data/nvdcve-1.1-2014.json.gz (deflated 2%)\n",
            "  adding: data/4.0/nvd_data/nvdcve-1.1-2008.json.gz (deflated 2%)\n",
            "  adding: data/4.0/nvd_data/nvdcve-1.1-2010.json.gz (deflated 1%)\n",
            "  adding: data/4.0/nvd_data/nvdcve-1.1-2018.json.gz (deflated 2%)\n",
            "  adding: data/4.0/nvd_data/nvdcve-1.1-2011.json.gz (deflated 1%)\n",
            "  adding: data/4.0/nvd_data/nvdcve-1.1-2015.json.gz (deflated 2%)\n",
            "  adding: data/4.0/nvd_data/nvdcve-1.1-2003.json.gz (stored 0%)\n",
            "  adding: data/4.0/nvd_data/nvdcve-1.1-2009.json.gz (deflated 1%)\n",
            "  adding: data/4.0/nvd_data/nvdcve-1.1-2006.json.gz (deflated 2%)\n",
            "  adding: data/4.0/nvd_data/nvdcve-1.1-2012.json.gz (deflated 2%)\n",
            "  adding: data/4.0/nvd_data/nvdcve-1.1-2002.json.gz (deflated 0%)\n",
            "  adding: data/4.0/nvd_data/nvdcve-1.1-2025.json.gz (deflated 0%)\n",
            "  adding: data/4.0/nvd_data/nvdcve-1.1-2019.json.gz (deflated 2%)\n",
            "  adding: data/4.0/garak/ (stored 0%)\n",
            "  adding: data/4.0/garak/garak.report.jsonl (deflated 85%)\n",
            "  adding: data/4.0/garak/garak_report_flat.csv (deflated 83%)\n",
            "  adding: data/4.0/garak/garak_with_severity_historic.csv (deflated 90%)\n",
            "  adding: models/ (stored 0%)\n",
            "  adding: models/4.0/ (stored 0%)\n",
            "  adding: models/4.0/best_cvss_classifier_historic.pkl (deflated 56%)\n",
            "  adding: models/4.0/cvss_label_encoder_historic.pkl (deflated 35%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf data/\n",
        "!rm -rf models/"
      ],
      "metadata": {
        "id": "P1cAatF2ZIXa"
      },
      "execution_count": 4,
      "outputs": []
    }
  ]
}